{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303029\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.225705\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.089896\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.081704\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.050931\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.051239\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.168388\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.066811\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.021731\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.011314\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 98.52%\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.120834\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.059694\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.063997\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.026672\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.024863\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.084564\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.034243\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.062646\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.012279\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.086770\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 98.74%\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.002467\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.078870\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.020717\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004841\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.012492\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.169444\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.006939\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.023678\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.051578\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.028585\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 98.90%\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.005364\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.099284\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.018958\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.019301\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.015532\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.007934\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.001683\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000337\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.005223\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.007801\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 99.13%\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.022630\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.002683\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.111906\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.002106\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.011714\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.017339\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.010485\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.041233\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.032336\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.053097\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 99.12%\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.030791\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.021742\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000258\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.010407\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.004749\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000462\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.010159\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.008424\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.004789\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.012588\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 98.63%\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002790\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.001477\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.019553\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.004018\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.007926\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.005706\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.050548\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000272\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.012312\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.000841\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 98.85%\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001188\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000994\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.010394\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000275\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000008\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.001868\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.009811\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.070912\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.001820\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.030961\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 99.05%\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.004419\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.016561\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.010723\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000543\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.049971\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.010277\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.002156\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000727\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.007088\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.002633\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 99.02%\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.002624\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.001772\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000862\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.003585\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000071\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000643\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.035110\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.026153\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.002905\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.006426\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 98.99%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define data transformations (normalization and conversion to tensors)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset for both training and testing, move data to GPU\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class SmallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "# Move model to GPU\n",
    "model = SmallNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data to GPU\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Train and test the model\n",
    "for epoch in range(1, 11):  # You can adjust the number of epochs as needed\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29428\\4002064643.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Load the pre-trained ResNet-18 model and modify it for MNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mresnet18\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomFcLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 10 classes for MNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomFcLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomFcLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Load the pre-trained ResNet-18 model and modify it for MNIST\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "num_features = resnet18.fc.in_features\n",
    "resnet18.fc = CustomFcLayer(num_features, 10)  # 10 classes for MNIST\n",
    "\n",
    "# Move the model to GPU\n",
    "model = resnet18.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Test loop\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data to GPU\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Train and test the model\n",
    "for epoch in range(1, 11):  # You can adjust the number of epochs as needed\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
